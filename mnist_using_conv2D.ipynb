{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_using_conv2D.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhuselvaraj/tensorflow_projects/blob/master/mnist_using_conv2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qHoXErBQoO5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we are going to use convolution of single layer to improve our training accuracy. we can consider images from fashion_mnist to proceed."
      ]
    },
    {
      "metadata": {
        "id": "mfBiuhH5hhG2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At first,import tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "xmO0sCzahgSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KROB1vyBiXTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "define mycallback() incase of it reaches an accuracy 99.8% inorder to stop the training"
      ]
    },
    {
      "metadata": {
        "id": "omARORo-imVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.998):\n",
        "      print(\"\\nReached 0.998 acc so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_syFSjwixHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Io-9WWYitoy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "downloading images as API from fashion_mnist and loading it as test and training images"
      ]
    },
    {
      "metadata": {
        "id": "I3-E7ShZjDE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QesNWrohjtPk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "reshaping our model for implementing convolution layer.(i.e) we cannot give the exact training set to conv2d and so reshaping it as we give for flatten()"
      ]
    },
    {
      "metadata": {
        "id": "N9cjMzzRjMGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images/255\n",
        "test_images=test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JC0M_e61kKOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "defining our model with conv2D 64 filters "
      ]
    },
    {
      "metadata": {
        "id": "7EmPTUJckUB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "372f0f3f-49a0-408d-fff6-c037758196f0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',input_shape = (28,28,1)),\n",
        "                                  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                  tf.keras.layers.Flatten(),\n",
        "                                   tf.keras.layers.Dense(128,activation = tf.nn.relu),                                   \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_uw8zLeqka41",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fit our training data and evaluating out test set"
      ]
    },
    {
      "metadata": {
        "id": "XqoId_agkXPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "7a2dd8c4-0069-4512-b127-25070c4acf94"
      },
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=20,callbacks=[callbacks])\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.1426 - acc: 0.9566\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0485 - acc: 0.9851\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0305 - acc: 0.9908\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0196 - acc: 0.9934\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0125 - acc: 0.9961\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0098 - acc: 0.9968\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.0083 - acc: 0.9973\n",
            "Epoch 8/20\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9980\n",
            "Reached 0.998 acc so cancelling training!\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0062 - acc: 0.9980\n",
            "10000/10000 [==============================] - 3s 312us/sample - loss: 0.0493 - acc: 0.9862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fBJT_yfjnH04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is our results. Training accuracy is about 99.8% and training loss is 0.0062.\n",
        "Test accuracy is about 98.62% and loss about 0.493 which is not bad i think!"
      ]
    }
  ]
}